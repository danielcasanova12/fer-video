# Inherit from the base config
_target_: hydra.compose
_recursive_: false

# Override parameters for the V2 experiment
name: "lstm_v2"
seed: 42 # Inherit or define a new seed for this config

dataset:
  name: ravdess_split
  root: "F:/Git/fer-video/fer-video/data"
  max_frames: 12
  frames_per_second: 1
  class_mappings:
    caer:       ['Anger','Disgust','Fear','Happy','Neutral','Sad','Surprise']
    cmu_moisei: ['angry','disgust','fear','happy','neutral','sad','surprised']
    ravdess:    ['angry','calm','disgust','fear','happy','neutral','sad','surprised']

model:
  model_type: video # Adicionado
  name: improved_lstm
  input_size: 512
  hidden_size: 256
  num_layers: 2
  dropout: 0.4
  cnn_backbone: resnet18
  freeze_cnn: false # This is the change for V2
  # ViT parameters (keep them even if not used by improved_lstm)
  model_name: "google/vit-base-patch16-224-in21k"
  pretrained: true
  freeze_backbone: true

training:
  batch_size: 8
  num_epochs: 50
  lr: 1e-4
  weight_decay: 1e-4
  num_workers: 4
  precision: 16
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  val_check_interval: 1
  log_interval: 10
  checkpoint_dir: "checkpoints/"
  log_dir: "logs/"
  early_stopping:
    enable: true
    patience: 10
  scheduler:
    name: cosine_annealing
    t_max: 50 # Should match num_epochs
    eta_min: 1e-6

wandb:
  enable: true
  entity: "snaxofc10-utfpr-medianeira"
  project: "fer_video"
